# -*- coding: utf-8 -*-
"""DMGS_DJT_964124.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KU7AgwwXnMuTb0ipTaY00fA70dSKKSGc
"""

# Importing necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE
import seaborn as sns
import matplotlib.pyplot as plt
# Set Seaborn style for better visual aesthetics
sns.set(style="whitegrid")
# Load the dataset
file_path = 'Healthcare Providers.csv'
data = pd.read_csv(file_path)

# Data preview
data.head()

# Basic information about the dataset
data.info()

# Summary statistics
data.describe()

# Check for missing values
missing_values = data.isnull().sum()
print("Missing Values:\n", missing_values[missing_values > 0])
# Drop rows with missing values for simplicity (could apply more complex imputation if needed)
data.dropna(inplace=True)

# Pie Chart: Gender Distribution
plt.figure(figsize=(7, 7))
data['Gender of the Provider'].value_counts().plot.pie(autopct='%1.1f%%', startangle=90, colors=['#ff9999', '#66b3ff'])
plt.title('Gender Distribution of Healthcare Providers')
plt.ylabel('')
plt.show()

# Bar Plot: Medicare Participation Indicator by Gender
plt.figure(figsize=(10, 6))
sns.countplot(x='Medicare Participation Indicator', hue='Gender of the Provider', data=data, palette='Set2')
plt.title('Medicare Participation Indicator by Gender')
plt.xlabel('Medicare Participation')
plt.ylabel('Count')
plt.show()

# Bar plot for Provider Type distribution
plt.figure(figsize=(10, 6))
sns.countplot(data=data, x='Provider Type', hue='Provider Type', palette='Set2')
plt.title('Distribution of Provider Types')
plt.xticks(rotation=45)
plt.xlabel('Provider Type')
plt.ylabel('Count')
plt.show()

# Data Preprocessing
# Replace commas in numeric columns and convert to float
numeric_columns = ['Number of Services', 'Number of Medicare Beneficiaries',
                   'Number of Distinct Medicare Beneficiary/Per Day Services',
                   'Average Medicare Allowed Amount', 'Average Submitted Charge Amount',
                   'Average Medicare Payment Amount', 'Average Medicare Standardized Amount']
for col in numeric_columns:
    data[col] = data[col].replace({',': ''}, regex=True).astype(float)
# Label Encoding for categorical variables
le = LabelEncoder()
data['Gender of the Provider'] = le.fit_transform(data['Gender of the Provider'])
data['Entity Type of the Provider'] = le.fit_transform(data['Entity Type of the Provider'])
data['Medicare Participation Indicator'] = le.fit_transform(data['Medicare Participation Indicator'])
data['Place of Service'] = le.fit_transform(data['Place of Service'])
data['HCPCS Drug Indicator'] = le.fit_transform(data['HCPCS Drug Indicator'])

# Selecting features and target variable
X = data[['Number of Services', 'Number of Medicare Beneficiaries',
          'Number of Distinct Medicare Beneficiary/Per Day Services',
          'Average Medicare Allowed Amount', 'Average Submitted Charge Amount',
          'Average Medicare Payment Amount', 'Average Medicare Standardized Amount']]
y = data['Medicare Participation Indicator']  # Example fraud indicator column
# Handling imbalanced data using SMOTE
sm = SMOTE(random_state=42)
X_resampled, y_resampled = sm.fit_resample(X, y)
# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)

# Function to visualize confusion matrix
def plot_confusion_matrix(y_true, y_pred, model_name, cmap="Blues"):
    """Plots the confusion matrix for a given model."""
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(6, 4))
    sns.heatmap(cm, annot=True, fmt="d", cmap=cmap, cbar=False)
    plt.title(f'Confusion Matrix for {model_name}')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

# Logistic Regression
print("Logistic Regression")
lr = LogisticRegression(max_iter=1000)
lr.fit(X_train, y_train)
y_pred_lr = lr.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred_lr))
print("Classification Report:\n", classification_report(y_test, y_pred_lr))
plot_confusion_matrix(y_test, y_pred_lr, "Logistic Regression")

# Random Forest
print("Random Forest")
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred_rf))
print("Classification Report:\n", classification_report(y_test, y_pred_rf))
plot_confusion_matrix(y_test, y_pred_rf, "Random Forest", cmap="Greens")

# Support Vector Machines (SVC)
print("Support Vector Machines (SVC)")
linear_svc = LinearSVC(random_state=42, dual=False)
linear_svc.fit(X_train, y_train)
y_pred_linear_svc = linear_svc.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred_linear_svc))
print("Classification Report:\n", classification_report(y_test, y_pred_linear_svc))
plot_confusion_matrix(y_test, y_pred_linear_svc, "SVC", cmap="Reds")

# Gradient Boosting
print("Gradient Boosting")
gb = GradientBoostingClassifier(n_estimators=100, random_state=42)
gb.fit(X_train, y_train)
y_pred_gb = gb.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred_gb))
print("Classification Report:\n", classification_report(y_test, y_pred_gb))
plot_confusion_matrix(y_test, y_pred_gb, "Gradient Boosting", cmap="Purples")

# Neural Networks (MLP)
print("Neural Networks")
nn = MLPClassifier(hidden_layer_sizes=(100,100), max_iter=500, random_state=42)
nn.fit(X_train, y_train)
y_pred_nn = nn.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred_nn))
print("Classification Report:\n", classification_report(y_test, y_pred_nn))
plot_confusion_matrix(y_test, y_pred_nn, "Neural Networks", cmap="Oranges")

# Summarizing accuracy of each model
models = {
    "Logistic Regression": accuracy_score(y_test, y_pred_lr),
    "Random Forest": accuracy_score(y_test, y_pred_rf),
    "SVC": accuracy_score(y_test, y_pred_linear_svc),
    "Gradient Boosting": accuracy_score(y_test, y_pred_gb),
    "Neural Networks": accuracy_score(y_test, y_pred_nn)
}
# Identify the best performing model
best_model_name = max(models, key=models.get)
best_model_accuracy = models[best_model_name]
print(f"Best Model: {best_model_name} with accuracy: {best_model_accuracy:.4f}")

# Plotting Accuracy Comparison
plt.figure(figsize=(10, 6))
plt.bar(models.keys(), models.values(), color=['blue', 'green', 'red', 'purple', 'orange'])
plt.title("Model Accuracy Comparison")
plt.ylabel("Accuracy")
plt.xticks(rotation=45)
plt.show()